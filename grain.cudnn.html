<!DOCTYPE html>
<html>
<head>
    <title>grain.cudnn (grain.cudnn)</title>
    <meta charset="utf-8" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
        <link rel="stylesheet" href="style.css" />
        <script type="text/javascript" src="script.js"></script>

    
    <link rel="prefetch" href="search-results.html" />
</head>
<body>
    <div id="page-header">
        <div id="logotype">
        <span>Documentation</span>
        <nav>
            <a href="https://github.com/ShigekiKarita/grain">GitHub</a>
            <a href="https://github.com/ShigekiKarita/grain/tree/master/example">Example</a>
            <a href="http://dlang.org/">Dlang.org</a>
        </nav>
        </div>

        <form action="search-docs.html" id="search">
            <input type="search" placeholder="Find a symbol name..." name="searchTerm" />
            <input type="submit" value="Go" />
        </form>
    </div>
    <div id="page-body">
        <div id="page-content">
        <h1>grain.cudnn</h1><div class="breadcrumbs"><a href="grain.html" class="breadcrumb">grain</a></div><div><div class="documentation-comment synopsis"><div><p>cuDNN high level wrapper for grain.autograd.Variable</p><p>TODO: support global workspace instead of frequent allocation</p></div></div></div><div class="annotated-prototype"></div><h2 id="members"><a href="#members" class="header-anchor">Members</a></h2><h3 id="function" class="member-list-header hide-from-toc"><a href="#function" class="header-anchor">Functions</a></h3><dl class="member-list native"><dt><a href="grain.cudnn.activationBackward.html">activationBackward</a><div style="max-width: 239ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">activationBackward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gx</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gy</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">y</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1.0</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0.0</span>, <span class="type">double</span> <span class="hid">coeff</span> = <span class="num">0.0</span>)</tt></div></dt><dd><div><p>grad function of sigmoid/tanh ... etc wrapper</p></div></dd><dt><a href="grain.cudnn.activationForward.html">activationForward</a><div style="max-width: 157ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">activationForward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">y</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1.0</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0.0</span>, <span class="type">double</span> <span class="hid">coeff</span> = <span class="num">0.0</span>)</tt></div></dt><dd><div><p>y = alpha * f(x) + beta * y</p></div></dd><dt><a href="grain.cudnn.convBackward.html">convBackward</a><div style="max-width: 481ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">convBackward</span><tt class="highlighted">(<span class="kwrd">ref</span> <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gradInput</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">input</span>, <span class="kwrd">ref</span> <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gradFilter</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">filter</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gradOutput</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">stride</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">pad</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">dilation</span>, <span class="type">int</span> <span class="hid">ngroup</span> = <span class="num">1</span>, <span class="hid">cudnnConvolutionBwdDataAlgo_t</span> <span class="hid">algo</span> = <span class="hid">CUDNN_CONVOLUTION_BWD_DATA_ALGO_1</span>, <span class="type">float</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="type">float</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>wrapper of cudnnConvolutionBackwardData and Weight for Variable</p></div></dd><dt><a href="grain.cudnn.convForward.html">convForward</a><div style="max-width: 386ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">convForward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">input</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">filter</span>, <span class="kwrd">ref</span> <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">output</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">stride</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">pad</span>, <span class="kwrd">const</span> <span class="type">int</span>[<span class="hid">imDims</span>] <span class="hid">dilation</span>, <span class="type">int</span> <span class="hid">ngroup</span> = <span class="num">1</span>, <span class="hid">cudnnConvolutionFwdAlgo_t</span> <span class="hid">algo</span> = <span class="hid">CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM</span>, <span class="type">float</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="type">float</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>wrapper of cudnnConvolutionForward for Variable</p></div></dd><dt><a href="grain.cudnn.cudnnDataType.html">cudnnDataType</a><div style="max-width: 23ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">cudnnDataType</span><tt class="highlighted">()</tt></div></dt><dd><div><p>convert floating point types (float, double) into cudnn enum</p></div></dd><dt><a href="grain.cudnn.fill.html">fill</a><div style="max-width: 59ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">fill</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>, <span class="hid">T</span> <span class="hid">value</span>)</tt></div></dt><dd><div><p>x[] = value (WARNING: not tested)</p></div></dd><dt><a href="grain.cudnn.isContiguous.html">isContiguous</a><div style="max-width: 51ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">bool</span></tt> <span class="name">isContiguous</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">Storage</span>) <span class="hid">x</span>)</tt></div></dt><dd><div><p>WIP</p></div></dd><dt><a href="grain.cudnn.isDeterministic.html">isDeterministic</a><div style="max-width: 25ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">isDeterministic</span><tt class="highlighted">()</tt></div></dt><dt><a href="grain.cudnn.isNanProp.html">isNanProp</a><div style="max-width: 18ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">isNanProp</span><tt class="highlighted">()</tt></div></dt><dd><div><p>return global cudnn option</p></div></dd><dt><a href="grain.cudnn.makeCudnnTensor.1.html">makeCudnnTensor</a><div style="max-width: 62ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">makeCudnnTensor</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>)</tt></div></dt><dd><div><p>convert variable to cudnn tensor discriptor object</p></div></dd><dt><a href="grain.cudnn.makeCudnnTensor.2.html">makeCudnnTensor</a><div style="max-width: 39ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">makeCudnnTensor</span><tt class="highlighted">(<span class="kwrd">ref</span> <span class="hid">T</span> <span class="hid">storage</span>)</tt></div></dt><dd><div><p>convert contiguous cuda storage to 1-D tensor disc</p></div></dd><dt><a href="grain.cudnn.poolBackward.html">poolBackward</a><div style="max-width: 353ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">poolBackward</span><tt class="highlighted">(<span class="kwrd">ref</span> <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">_tensorDims</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gradInput</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">_tensorDims</span>, <span class="hid">DeviceStorage</span>) <span class="hid">input</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">_tensorDims</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gradOutput</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">_tensorDims</span>, <span class="hid">DeviceStorage</span>) <span class="hid">output</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">windowDim</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">padding</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">stride</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>wrapper of cudnnPoolingBackward for Variable</p></div></dd><dt><a href="grain.cudnn.poolForward.html">poolForward</a><div style="max-width: 179ch;" class="simplified-prototype"><span class="lang-feature">auto</span>  <span class="name">poolForward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">_tensorDims</span>, <span class="hid">DeviceStorage</span>) <span class="hid">input</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">windowDim</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">padding</span>, <span class="type">int</span>[<span class="hid">_poolDims</span>] <span class="hid">stride</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>wrapper of cudnnPoolingForward for Variable</p></div></dd><dt><a href="grain.cudnn.reduce.html">reduce</a><div style="max-width: 123ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">reduce</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">src</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">dst</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>Tensor operation : C = reduce op( alpha * A ) + beta * C</p></div></dd><dt><a href="grain.cudnn.scale.html">scale</a><div style="max-width: 60ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">scale</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>, <span class="hid">T</span> <span class="hid">alpha</span>)</tt></div></dt><dd><div><p>x = alpha x</p></div></dd><dt><a href="grain.cudnn.softmaxBackward.html">softmaxBackward</a><div style="max-width: 174ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">softmaxBackward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gx</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">gy</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">y</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1.0</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0.0</span>)</tt></div></dt><dd><div><p>grad of softmax</p></div></dd><dt><a href="grain.cudnn.softmaxForward.html">softmaxForward</a><div style="max-width: 132ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">softmaxForward</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">x</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">y</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1.0</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0.0</span>)</tt></div></dt><dd><div><p>compute the softmax over all C for each H, W, N</p></div></dd><dt><a href="grain.cudnn.tensorOp.html">tensorOp</a><div style="max-width: 177ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">tensorOp</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">c</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">a</span>, <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">b</span>, <span class="hid">T</span> <span class="hid">alpha1</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">alpha2</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>Tensor operation : C = op( alpha1 * A, alpha2 * B ) + beta * C</p></div></dd><dt><a href="grain.cudnn.transform.html">transform</a><div style="max-width: 130ch;" class="simplified-prototype"><tt class="highlighted"><span class="type">void</span></tt> <span class="name">transform</span><tt class="highlighted">(<span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">src</span>, <span class="kwrd">ref</span> <span class="hid">Variable</span>!(<span class="hid">T</span>, <span class="hid">dim</span>, <span class="hid">DeviceStorage</span>) <span class="hid">dst</span>, <span class="hid">T</span> <span class="hid">alpha</span> = <span class="num">1</span>, <span class="hid">T</span> <span class="hid">beta</span> = <span class="num">0</span>)</tt></div></dt><dd><div><p>copy src to dst with broadcasting</p></div></dd></dl><h3 id="struct" class="member-list-header hide-from-toc"><a href="#struct" class="header-anchor">Structs</a></h3><dl class="member-list native"><dt><a href="grain.cudnn.TensorDesc.html">TensorDesc</a><div style="max-width: 18ch;" class="simplified-prototype"><span class="builtin-type">struct</span> <span class="name">TensorDesc</span></div></dt><dd><div><p>cudnn data type of variable like struct</p></div></dd><dt><a href="grain.cudnn.ThreadLocalDropout.html">ThreadLocalDropout</a><div style="max-width: 27ch;" class="simplified-prototype"><span class="builtin-type">struct</span> <span class="name">ThreadLocalDropout</span></div></dt><dd><div><p>Global (thread local) dropout state with descriptor and state array</p></div></dd></dl><div><h2 id="meta"><a href="#meta" class="header-anchor">Meta</a></h2><div class="documentation-comment source-section other-section"><h3 id="source"><a href="#source" class="header-anchor">Source</a></h3><div><p><a href="source/grain.cudnn.d.html">See Source File</a><br /></p></div></div></div></div>
        <div id="page-nav"><a href="grain.html" class="parent">grain</a>
        <span class="type-separator">modules</span><ul><li><a href="grain.autograd.html" class="module">autograd</a></li><li><a href="grain.chain.html" class="module">chain</a></li><li><a href="grain.config.backprop.html" class="module">config</a></li><li><a href="grain.cublas.html" class="module">cublas</a></li><li><a href="grain.cuda.html" class="module">cuda</a></li><li><a href="grain.cudnn.html" class="module current">cudnn</a></li><li><a href="grain.dataset.html" class="module">dataset</a></li><li><a href="grain.functions.html" class="module">functions</a></li><li><a href="grain.hdf5.html" class="module">hdf5</a></li><li><a href="grain.metric.html" class="module">metric</a></li><li><a href="grain.optim.html" class="module">optim</a></li><li><a href="grain.serializer.html" class="module">serializer</a></li><li><a href="grain.testing.html" class="module">testing</a></li><li><a href="grain.utility.html" class="module">utility</a></li><li><a href="grain.warpctc.html" class="module">warpctc</a></li></ul></div>
    </div>
    <div id="page-footer">
        Distributed under <a href="https://www.boost.org/users/license.html">BSL-1.0</a>.
        Copyright <a href="https://shigekikarita.github.io">Shigeki Karita</a> 2018.
        Page generated by <a href="https://github.com/adamdruppe/adrdox">adrdox</a>
    </div>
</body>
</html>